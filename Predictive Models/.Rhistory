##############################Score plots
datapath = "/home/bic/rthomas/Desktop/Link to 12CellLinesPaper/output_June11/2weeksoutputRT/2weeks_combined_sampled.csv.csv"
datapath_test = "/home/bic/rthomas/Desktop/Link to 12CellLinesPaper/output_June11/2weeksoutputRT/2weeks_combined_subsample_sampled.csv.csv_sampled.csv.csv"
Predictees <- c("Score")
features <- c("Dapi.intensity",
"Dapi.area",
"Dapi.area.fraction.in.nuclei",
"Ch1.positive",
"Ch1.intensity",
"Ch1.area",
"all.negative",
"X.nuclei",
"too.small...75.",
"too.big...250.",
"size.average",
"Column",
"Media")
# Set seed for reproducibility
set.seed(42)
df <- read.csv(datapath)
colnames(df)
# load libraries
library(plot3D)
library(ggplot2)
library(tidyverse)
library(caret)
library(leaps)
library(MASS)
ggplotRegression <- function (fit, index) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[index], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste(" Slope =",signif(fit$coef[[index]], 5),
" P =",signif(summary(fit)$coef[index,4], 5)))
}
data_step <- df[,colSums(is.na(df))<nrow(df)]
data_step <- data_step[rowSums(is.na(data_step)) == 0,]
for (Predictee in Predictees) {
variables = paste(Predictee, " ~ ",paste(features,collapse = "+"))
paste(
Predictee,
" ~
Dapi.intensity +
Dapi.area +
Dapi.area.fraction.in.nuclei +
Ch1.positive +
Ch1.intensity +
Ch1.area +
all.negative +
X.nuclei +
too.small...75. +
too.big...250. +
size.average
"
)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(as.formula(variables),
data = data_step,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:12),
trControl = train.control
)
print(step.model$results)
print(step.model$bestTune)
print(summary(step.model$finalModel))
modelfeatures  <- rownames(as.data.frame(coef(step.model$finalModel, step.model$bestTune$nvmax)))[-1]
lmodel <- lm(as.formula(paste(Predictee, " ~ ",paste(modelfeatures,collapse = "+"))), data_step)
print(ggplot(step.model))
for (i in 1:step.model$bestTune$nvmax+1){
print(ggplotRegression(lmodel, i))
}
par(mfrow=c(2,2)) # Change the panel layout to 2 x 2
plot(lmodel)
par(mfrow=c(1,1)) # Change back to 1 x 1
pred <- predict(lmodel, data_step)
print(summary (lmodel))
print(AIC (lmodel))
actuals_preds <- data.frame(cbind(actuals=data_step[[Predictee]], predicteds=pred))  # make actuals_predicteds dataframe.
correlation_accuracy <- cor(actuals_preds)
minmax <-  mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))  #min_max accuracy
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)  #mean absolute percent deviation
print (ggplot(actuals_preds, aes_string(x= "actuals", y = "predicteds")) +
geom_point() +
geom_smooth(method = lm) +
labs(title = paste(Predictee, "           ", "Min-Max Accuracy: ",minmax, "       " ,
"Mean Absolute Percentage Error: ",mape))
)
#test data
df_test <- read.csv(datapath_test)
data_step_test <- df[,colSums(is.na(df))<nrow(df)]
data_step_test <- data_step_test[rowSums(is.na(data_step)) == 0,]
pred_test <- predict(lmodel, data_step_test)
print(summary (lmodel))
print(AIC (lmodel))
actuals_preds_test <- data.frame(cbind(actuals=data_step_test[[Predictee]], predicteds=pred_test))  # make actuals_predicteds dataframe.
correlation_accuracy <- cor(actuals_preds_test)
minmax_test <-  mean(apply(actuals_preds_test, 1, min) / apply(actuals_preds_test, 1, max))  #min_max accuracy
mape_test <- mean(abs((actuals_preds_test$predicteds - actuals_preds_test$actuals))/actuals_preds_test$actuals)  #mean absolute percent deviation
print (ggplot(actuals_preds_test, aes_string(x= "actuals", y = "predicteds")) +
geom_point() +
geom_smooth(method = lm) +
labs(title = paste(Predictee, "           ", "Min-Max Accuracy: ",minmax_test, "       " ,
"Mean Absolute Percentage Error: ",mape_test))
)
hist(actuals_preds_test$predicteds, 100)
}
data_step$Grade <- data_step$Ch1.intensity / data_step$Dapi.intensity
postResample(pred = pred_test, obs = actuals_preds_test$actuals)
